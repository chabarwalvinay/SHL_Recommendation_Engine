{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b1e45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from retrieval.search import search\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "BASE_DIR = Path(__file__).resolve().parents[1]\n",
    "\n",
    "EXCEL_FILE = BASE_DIR / \"data\" / \"train_test_data\" / \"Gen_AI Dataset (1).xlsx\"\n",
    "TRAIN_SHEET = \"train-set\"\n",
    "\n",
    "OUTPUT_CSV = BASE_DIR / \"data\" / \"retrieval_eval.csv\"\n",
    "\n",
    "K_VALUES = [10, 20, 30, 50]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# LOAD TRAIN DATA\n",
    "# =========================================================\n",
    "print(\"ðŸ”¹ Loading training dataset...\")\n",
    "\n",
    "df = pd.read_excel(EXCEL_FILE, sheet_name=TRAIN_SHEET)\n",
    "\n",
    "# Expecting columns: query, assessment_url\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "assert \"query\" in df.columns\n",
    "assert \"assessment_url\" in df.columns\n",
    "\n",
    "# Group URLs per query\n",
    "query_to_urls = defaultdict(set)\n",
    "for _, row in df.iterrows():\n",
    "    query_to_urls[row[\"query\"].strip()].add(row[\"assessment_url\"].strip())\n",
    "\n",
    "queries = list(query_to_urls.items())\n",
    "\n",
    "print(f\"ðŸ”¹ Unique queries: {len(queries)}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# EVALUATION\n",
    "# =========================================================\n",
    "results = []\n",
    "\n",
    "print(\"ðŸ”¹ Running Phase-2 recall evaluation...\")\n",
    "\n",
    "for query, true_urls in tqdm(queries):\n",
    "    retrieved = search(query)\n",
    "\n",
    "    retrieved_urls = [\n",
    "        r[\"assessment_id\"] for r in retrieved\n",
    "    ]\n",
    "\n",
    "    row = {\n",
    "        \"query\": query,\n",
    "        \"num_relevant\": len(true_urls),\n",
    "    }\n",
    "\n",
    "    for k in K_VALUES:\n",
    "        top_k = retrieved_urls[:k]\n",
    "        hit = any(url in top_k for url in true_urls)\n",
    "        row[f\"recall@{k}\"] = int(hit)\n",
    "\n",
    "    results.append(row)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# AGGREGATE METRICS\n",
    "# =========================================================\n",
    "eval_df = pd.DataFrame(results)\n",
    "\n",
    "summary = {\n",
    "    f\"recall@{k}\": eval_df[f\"recall@{k}\"].mean()\n",
    "    for k in K_VALUES\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ”¹ Phase-2 Recall Summary\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v:.3f}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# SAVE RESULTS\n",
    "# =========================================================\n",
    "eval_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"\\nâœ… Saved evaluation results to: {OUTPUT_CSV}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
